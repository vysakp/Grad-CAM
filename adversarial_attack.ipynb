{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "swLVD57Unzkc"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "\n",
        "EPS = 2 / 255.0\n",
        "LR = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "m1ce-yolnWDJ"
      },
      "outputs": [],
      "source": [
        "def preprocess_image(image,dim=(224,224)):\n",
        "    # swap color channels, resize the input image, and add a batch dimension\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.resize(image, dim)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "LndLKhfY0LRU"
      },
      "outputs": [],
      "source": [
        "def get_class_idx(class_name):\n",
        "  import urllib.request\n",
        "  import json\n",
        "\n",
        "  url = 'https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json'\n",
        "  response = urllib.request.urlopen(url)\n",
        "  class_names = json.loads(response.read())\n",
        "  for i in range(len(class_names)):\n",
        "    if class_names[i] == class_name:\n",
        "      return i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "t2_VVnvyo1Jk"
      },
      "outputs": [],
      "source": [
        "def predict(model,image,decode_predictions):\n",
        "  predictions = model.predict(image)\n",
        "  predictions = decode_predictions(predictions, top=3)[0]\n",
        "  label = predictions[0][1]\n",
        "  confidence = predictions[0][2] * 100\n",
        "  print(\"[INFO] label: {} confidence: {:.2f}%\".format(label, confidence))\n",
        "  return label.replace('_', ' ')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "IlO-_MH5nYsp"
      },
      "outputs": [],
      "source": [
        "def clip_eps(tensor, eps):\n",
        "    return tf.clip_by_value(tensor, clip_value_min=-eps, clip_value_max=eps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "t3FGWLbZnZN-"
      },
      "outputs": [],
      "source": [
        "def generate_adversaries(model, baseImage, delta, classIdx, steps=50):\n",
        "    optimizer = Adam(learning_rate=LR)\n",
        "    sccLoss = SparseCategoricalCrossentropy() \n",
        "    for step in range(0, steps):\n",
        "        with tf.GradientTape() as tape:\n",
        "            tape.watch(delta)\n",
        "            adversary = preprocess_input(baseImage + delta)\n",
        "            predictions = model(adversary, training=False)\n",
        "            loss = -sccLoss(tf.convert_to_tensor([classIdx]), predictions)\n",
        "            if step % 5 == 0:\n",
        "                print(\"step: {}, loss: {}...\".format(step, loss.numpy()))\n",
        "\n",
        "        gradients = tape.gradient(loss, delta)\n",
        "        optimizer.apply_gradients([(gradients, delta)])\n",
        "        delta.assign_add(clip_eps(delta, eps=EPS))\n",
        "    return delta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "zIPaSiVyoXGD"
      },
      "outputs": [],
      "source": [
        "def attack(image,classIdx,output):\n",
        "  baseImage = tf.constant(image, dtype=tf.float32)\n",
        "  delta = tf.Variable(tf.zeros_like(baseImage), trainable=True)\n",
        "\n",
        "  print(\"[INFO] generating perturbation...\")\n",
        "  deltaUpdated = generate_adversaries(model, baseImage, delta, classIdx)\n",
        "  print(\"[INFO] creating adversarial example...\")\n",
        "  adverImage = (baseImage + deltaUpdated).numpy().squeeze()\n",
        "  adverImage = np.clip(adverImage, 0, 255).astype(\"uint8\")\n",
        "  adverImage = cv2.cvtColor(adverImage, cv2.COLOR_RGB2BGR)\n",
        "  cv2.imwrite(output, adverImage)\n",
        "\n",
        "  # save the noise vector as an image\n",
        "  noiseImage = deltaUpdated.numpy().squeeze()\n",
        "  noiseImage = np.clip((noiseImage + 0.5) * 255, 0, 255).astype(\"uint8\")\n",
        "  noiseImage = cv2.cvtColor(noiseImage, cv2.COLOR_RGB2BGR)\n",
        "  noiseOutput = os.path.splitext(output)[0] + '_noise.jpg'\n",
        "  cv2.imwrite(noiseOutput, noiseImage)\n",
        "  return baseImage + deltaUpdated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "olWbd4GAugrb"
      },
      "outputs": [],
      "source": [
        "def run(model,input,output,dim=(224,224)):\n",
        "  print(\"[INFO] running inference on the original image...\")\n",
        "  image = cv2.imread(input)\n",
        "  image = preprocess_image(image,dim)\n",
        "  preprocessedImage = preprocess_input(image)\n",
        "  label = predict(model,preprocessedImage,decode_predictions)\n",
        "  classIdx = get_class_idx(label)\n",
        "  print()\n",
        "\n",
        "  adverImage = attack(image,classIdx,output)\n",
        "  print(\"[INFO] running inference on the adversarial example...\")\n",
        "  preprocessedImage = preprocess_input(adverImage)\n",
        "  predict(model,preprocessedImage,decode_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4ZFtUnrf3J-",
        "outputId": "3bc078d1-7475-46f0-abc4-8c6483d5cca4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-05-07 15:49:25--  https://raw.githubusercontent.com/utkuozbulak/pytorch-cnn-adversarial-attacks/master/input_images/apple.JPEG\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5160 (5.0K) [image/jpeg]\n",
            "Saving to: ‘apple.JPEG.2’\n",
            "\n",
            "\rapple.JPEG.2          0%[                    ]       0  --.-KB/s               \rapple.JPEG.2        100%[===================>]   5.04K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-07 15:49:25 (76.8 MB/s) - ‘apple.JPEG.2’ saved [5160/5160]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/utkuozbulak/pytorch-cnn-adversarial-attacks/master/input_images/apple.JPEG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ckk2zZ4nuHg",
        "outputId": "30727fe6-ced2-4e61-d708-6ce2beeec4c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] loading pre-trained ResNet50 model...\n",
            "[INFO] running inference on the original image...\n",
            "1/1 [==============================] - 1s 883ms/step\n",
            "[INFO] label: Granny_Smith confidence: 87.95%\n",
            "\n",
            "[INFO] generating perturbation...\n",
            "step: 0, loss: -0.1284576654434204...\n",
            "step: 5, loss: -6.641036033630371...\n",
            "step: 10, loss: -15.304479598999023...\n",
            "step: 15, loss: -23.006061553955078...\n",
            "step: 20, loss: -31.427316665649414...\n",
            "step: 25, loss: -40.05393981933594...\n",
            "step: 30, loss: -47.87111282348633...\n",
            "step: 35, loss: -56.047882080078125...\n",
            "step: 40, loss: -63.69990158081055...\n",
            "step: 45, loss: -70.79307556152344...\n",
            "[INFO] creating adversarial example...\n",
            "[INFO] running inference on the adversarial example...\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "[INFO] label: saltshaker confidence: 100.00%\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.applications.resnet50 import decode_predictions,preprocess_input\n",
        "\n",
        "print(\"[INFO] loading pre-trained ResNet50 model...\")\n",
        "model = ResNet50(weights=\"imagenet\")\n",
        "run(model,input = '/content/apple.JPEG',output = '/content/dogncat_adv_resnet.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFWojSL4fHd_",
        "outputId": "75662f18-d16f-4c62-fb3b-7dd73e8253ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] loading pre-trained VGG16 model...\n",
            "[INFO] running inference on the original image...\n",
            "1/1 [==============================] - 0s 139ms/step\n",
            "[INFO] label: Granny_Smith confidence: 79.19%\n",
            "\n",
            "[INFO] generating perturbation...\n",
            "step: 0, loss: -0.23330824077129364...\n",
            "step: 5, loss: -1.8835047483444214...\n",
            "step: 10, loss: -4.744152069091797...\n",
            "step: 15, loss: -8.235982894897461...\n",
            "step: 20, loss: -12.371561050415039...\n",
            "step: 25, loss: -16.82699203491211...\n",
            "step: 30, loss: -21.407878875732422...\n",
            "step: 35, loss: -26.699193954467773...\n",
            "step: 40, loss: -32.87017059326172...\n",
            "step: 45, loss: -39.921207427978516...\n",
            "[INFO] creating adversarial example...\n",
            "[INFO] running inference on the adversarial example...\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "[INFO] label: whistle confidence: 100.00%\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import decode_predictions,preprocess_input\n",
        "\n",
        "print(\"[INFO] loading pre-trained VGG16 model...\")\n",
        "model = VGG16(weights=\"imagenet\")\n",
        "run(model,input='/content/apple.JPEG',output = '/content/apple_adv_vgg16.png')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
